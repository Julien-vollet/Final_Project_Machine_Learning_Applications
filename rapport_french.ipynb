{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616b166b",
   "metadata": {},
   "source": [
    "# Final Project ‚Äì Machine Learning Applications \n",
    "## Julien VOLLET\n",
    "\n",
    "## Introduction\n",
    "\n",
    "L‚Äôanalyse automatique de documents textuels est devenue un enjeu central dans de nombreux domaines tels que la veille d‚Äôinformation, la recommandation personnalis√©e, ou encore l‚Äôanalyse d‚Äôopinion. Dans ce contexte, le projet que nous avons men√© s‚Äôinscrit dans le cadre du cours \"Applications de l‚Äôapprentissage automatique\", et a pour objectif de mettre en ≈ìuvre une cha√Æne compl√®te de traitement de donn√©es textuelles, depuis le pr√©traitement jusqu‚Äô√† la visualisation interactive des r√©sultats.\n",
    "\n",
    "Nous avons choisi de travailler sur un jeu de donn√©es issu de TripAdvisor, centr√© sur des restaurants situ√©s en France. Ce jeu de donn√©es contient des informations textuelles descriptives associ√©es √† chaque √©tablissement (comme des mots-cl√©s, types de cuisine, ambiance, etc.), ainsi que des variables num√©riques telles que la note moyenne ou le nombre d‚Äôavis.\n",
    "\n",
    "Le projet se structure autour de plusieurs t√¢ches successives :\n",
    "\n",
    "- **Task 1** : Traitement des donn√©es textuelles (`keywords`) et vectorisation √† l‚Äôaide de plusieurs techniques (TF-IDF, Word2Vec, etc.), ainsi qu‚Äôune mod√©lisation th√©matique bas√©e sur LDA.\n",
    "- **Task 2.1** : Construction d‚Äôun mod√®le de classification supervis√©e visant √† pr√©dire si un restaurant est bien not√© √† partir de ses descripteurs textuels.\n",
    "- **Task 3** : D√©veloppement d‚Äôun tableau de bord interactif avec Dash permettant d‚Äôexplorer les th√®mes extraits automatiquement et leur distribution g√©ographique.\n",
    "\n",
    "Au travers de ce projet, nous avons appliqu√© de mani√®re concr√®te les concepts vus en cours : nettoyage de donn√©es textuelles, vectorisation, s√©lection de caract√©ristiques, mod√©lisation supervis√©e et non supervis√©e, visualisation dynamique et √©valuation rigoureuse des performances. Ce rapport retrace l‚Äôensemble de cette d√©marche, ainsi que les choix techniques et m√©thodologiques que nous avons faits tout au long du processus.\n",
    "\n",
    "\n",
    "## 1. Task 1 ‚Äì Traitement du langage naturel, vectorisation et mod√©lisation th√©matique\n",
    "\n",
    "### 1.1 Description du jeu de donn√©es\n",
    "\n",
    "Le jeu de donn√©es utilis√© provient d‚Äôun extrait public du site TripAdvisor, contenant des informations sur plus de 10 000 restaurants en Europe. Pour cadrer notre projet, nous avons filtr√© les donn√©es pour ne conserver que les restaurants situ√©s en **France**.\n",
    "\n",
    "Les variables retenues apr√®s nettoyage sont :\n",
    "\n",
    "- `restaurant_name` : nom du restaurant  \n",
    "- `city`, `address` : localisation  \n",
    "- `latitude`, `longitude` : coordonn√©es g√©ographiques  \n",
    "- `cuisines`, `special_diets`, `features`, `atmosphere` : cat√©gories textuelles  \n",
    "- `avg_rating` : note moyenne (0 √† 5)  \n",
    "- `total_reviews_count` : nombre d‚Äôavis  \n",
    "- `keywords` : mots-cl√©s qualitatifs associ√©s au restaurant  \n",
    "\n",
    "Apr√®s suppression des doublons et des lignes incompl√®tes, le dataset final contient environ **X restaurants uniques** r√©partis sur **Y villes fran√ßaises**. La variable `keywords`, qui est textuelle, a √©t√© utilis√©e comme base principale pour la vectorisation et l‚Äôanalyse th√©matique.\n",
    "\n",
    "**Illustration :**  \n",
    "Un exemple de mots-cl√©s pour un restaurant :\n",
    "> `[\"vegetarian friendly\", \"romantic\", \"gluten free options\", \"terrace\", \"wine bar\"]`\n",
    "\n",
    "Nous avons observ√© une grande diversit√© s√©mantique dans ces descripteurs, rendant n√©cessaire un pipeline de traitement rigoureux.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Pipeline de pr√©traitement des textes\n",
    "\n",
    "Le pr√©traitement s‚Äôest concentr√© sur la colonne `keywords`. Celle-ci contient des cha√Ænes textuelles repr√©sentant des attributs qualitatifs. L‚Äôobjectif du nettoyage est d‚Äôuniformiser et de simplifier ces donn√©es avant leur vectorisation.\n",
    "\n",
    "Les √©tapes appliqu√©es sont :\n",
    "\n",
    "- **Passage en minuscules** : uniformisation des termes  \n",
    "- **Suppression de la ponctuation** : nettoyage des caract√®res sp√©ciaux  \n",
    "- **Suppression de stopwords personnalis√©s** : mots tr√®s fr√©quents et peu discriminants comme \"the\", \"in\", \"with\"  \n",
    "- **Tokenisation** : d√©coupage des mots-cl√©s en tokens via un `split()` simple\n",
    "\n",
    "**Exemple (avant/apr√®s) :**\n",
    "\n",
    "| Texte original                                      | Apr√®s nettoyage                    |\n",
    "|-----------------------------------------------------|-------------------------------------|\n",
    "| `\"Gluten Free Options, Good for Groups, Cozy\"`      | `\"gluten free options good groups cozy\"` |\n",
    "\n",
    "Chaque restaurant est ainsi repr√©sent√© par une liste de **tokens courts et sp√©cifiques**, utilis√©s comme base pour la vectorisation.\n",
    "\n",
    "Nous avons √©galement analys√© la distribution du nombre de tokens (mots-cl√©s nettoy√©s) par restaurant, ce qui permet de valider l‚Äôhomog√©n√©it√© et la densit√© de l‚Äôinformation textuelle disponible.\n",
    "\n",
    "![Distribution de tokens](rapport/nb_token.png)\n",
    "\n",
    "> *Figure : Histogramme du nombre de mots-cl√©s (tokens) par restaurant apr√®s nettoyage. La majorit√© des √©tablissements poss√®dent entre 6 et 9 tokens.*\n",
    "\n",
    "\n",
    "Cette distribution montre une **concentration nette autour de 6 √† 9 mots-cl√©s par restaurant**, ce qui refl√®te une certaine standardisation dans la mani√®re dont les √©tablissements sont d√©crits. Tr√®s peu de restaurants en poss√®dent moins de 5 ou plus de 10, ce qui indique une **densit√© d‚Äôinformation raisonnablement constante** entre les observations.\n",
    "\n",
    "Cette r√©gularit√© est un atout pour l‚Äôapprentissage automatique : elle garantit que la plupart des entr√©es disposent d‚Äôun volume suffisant de descripteurs pour permettre une vectorisation stable et une interpr√©tation fiable. Elle justifie √©galement notre choix de recourir √† des m√©thodes comme TF-IDF ou LDA, qui supposent un minimum de contenu lexical pour produire des r√©sultats pertinents.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Choix de **ne pas utiliser de lemmatisation**\n",
    "\n",
    "Nous avons d√©lib√©r√©ment exclu la lemmatisation pour les raisons suivantes :\n",
    "\n",
    "- Les `keywords` sont des **phrases fixes** (ex. : \"wine bar\", \"family friendly\"), et leur modification pourrait alt√©rer le sens.\n",
    "- Les variantes morphologiques sont **rares** dans ce contexte (pas de \"run/running/ran\").\n",
    "- Des expressions apparemment proches comme `\"drinks available\"` et `\"drink bar\"` ont des sens diff√©rents ‚Äî la lemmatisation risquerait de **fusionner des entit√©s non √©quivalentes**.\n",
    "\n",
    "Nous avons donc choisi une approche **minimaliste mais s√©mantiquement s√ªre** pour conserver la richesse originale des mots-cl√©s.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 M√©thodes de vectorisation explor√©es\n",
    "\n",
    "Nous avons test√© plusieurs techniques de vectorisation afin de capturer la diversit√© s√©mantique des mots-cl√©s. Ces m√©thodes permettent de transformer les documents en vecteurs num√©riques exploitables par des mod√®les de machine learning.\n",
    "\n",
    "### 1.3 M√©thodes de vectorisation explor√©es\n",
    "\n",
    "Afin de transformer les donn√©es textuelles en repr√©sentations num√©riques exploitables par des algorithmes de machine learning, nous avons test√© plusieurs techniques de vectorisation adapt√©es aux textes courts et sp√©cialis√©s que sont les `keywords`.\n",
    "\n",
    "####  TF-IDF (Term Frequency ‚Äì Inverse Document Frequency)\n",
    "\n",
    "Le TF-IDF est une m√©thode pond√©r√©e qui attribue √† chaque mot une importance proportionnelle √† sa fr√©quence dans un document, mais inversement proportionnelle √† sa fr√©quence dans l‚Äôensemble du corpus. Autrement dit, les mots sp√©cifiques √† un restaurant seront mieux valoris√©s que les mots trop fr√©quents. Nous avons utilis√© l‚Äôimpl√©mentation `TfidfVectorizer` de Scikit-learn, qui produit une matrice creuse de grande dimension (~5000 tokens uniques). Cette m√©thode s‚Äôest av√©r√©e rapide, stable et bien adapt√©e √† notre contexte, car elle ne n√©cessite pas d‚Äôapprentissage pr√©alable et conserve une bonne capacit√© discriminante.\n",
    "\n",
    "####  Bag of Words (BoW)\n",
    "\n",
    "Le mod√®le BoW repose sur un principe simple : compter combien de fois chaque mot appara√Æt dans un document, sans prendre en compte ni le contexte ni l‚Äôordre des mots. Sa mise en ≈ìuvre avec `CountVectorizer` en fait une m√©thode tr√®s rapide, mais souvent trop na√Øve. Elle ne distingue pas les mots fr√©quents pertinents de ceux qui sont banals, et produit une repr√©sentation qui peut √™tre bruit√©e si le vocabulaire est trop g√©n√©rique. Cela dit, elle reste utile pour des mod√®les simples comme Naive Bayes.\n",
    "\n",
    "####  Word2Vec\n",
    "\n",
    "Word2Vec est une m√©thode de plongement lexical, introduite par Google, qui encode chaque mot sous forme d‚Äôun vecteur dense appris par le contexte dans lequel il appara√Æt. Dans notre projet, nous avons entra√Æn√© un mod√®le Word2Vec avec Gensim. Chaque mot est repr√©sent√© par un vecteur dense de dimension 100, et un document est repr√©sent√© par la moyenne des vecteurs de ses mots. Bien que plus riche s√©mantiquement, cette m√©thode n√©cessite un apprentissage pr√©alable et devient moins efficace si le corpus est limit√© ou peu vari√©, comme c‚Äôest le cas ici.\n",
    "\n",
    "####  Doc2Vec\n",
    "\n",
    "Doc2Vec est une extension de Word2Vec qui apprend directement un vecteur dense propre √† chaque document, en plus des vecteurs mots. Cela permet de capturer la structure globale d‚Äôun texte. Chaque restaurant est associ√© √† un `TaggedDocument`. Doc2Vec est plus adapt√© √† des documents longs ou complexes, mais dans notre cas, les gains obtenus n‚Äôont pas justifi√© le co√ªt de calcul et la complexit√© suppl√©mentaire.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### 1.4 Mod√©lisation th√©matique avec LDA\n",
    "\n",
    "Nous avons explor√© la d√©tection automatique de **sujets latents** (topics) dans les documents via l‚Äôalgorithme **Latent Dirichlet Allocation (LDA)**.\n",
    "\n",
    "#### 1.4.1 LDA avec Gensim\n",
    "\n",
    "- Cr√©ation d‚Äôun dictionnaire et d‚Äôun corpus bag-of-words.\n",
    "- Entra√Ænement de plusieurs mod√®les LDA avec **2 √† 20 sujets**.\n",
    "- √âvaluation via le **score de coh√©rence `c_v`**.\n",
    "- Le score optimal a √©t√© atteint pour **K = X** sujets.\n",
    "\n",
    "**Graphique** : Score de coh√©rence en fonction du nombre de topics\n",
    "\n",
    "#### 1.4.2 LDA avec Scikit-learn\n",
    "\n",
    "Nous avons √©galement impl√©ment√© une version de LDA √† l‚Äôaide de Scikit-learn. Les `keywords` ont √©t√© vectoris√©s via `CountVectorizer`, puis un mod√®le `LatentDirichletAllocation` a √©t√© entra√Æn√© avec **K = 6** sujets, d√©termin√© comme optimal apr√®s exp√©rimentation. Chaque restaurant a √©t√© associ√© √† un **topic dominant**, √† partir de la distribution de probabilit√© g√©n√©r√©e.\n",
    "\n",
    "Pour chaque topic, nous avons extrait les **10 mots-cl√©s les plus repr√©sentatifs** et identifi√© un **th√®me g√©n√©ral** interpr√©table :\n",
    "\n",
    "| Topic | Th√®me g√©n√©ral                   | Mots-cl√©s dominants                                                |\n",
    "|-------|----------------------------------|---------------------------------------------------------------------|\n",
    "| 0     | **Vin et ambiance romantique**   | `\"wine\", \"romantic\", \"cozy\", \"fine dining\", \"bar\", \"terrace\"`      |\n",
    "| 1     | **Restauration rapide / urbaine**| `\"cheap\", \"fast\", \"burger\", \"takeaway\", \"quick\", \"snack\"`          |\n",
    "| 2     | **Cuisine sant√© et r√©gimes**     | `\"vegan\", \"gluten\", \"healthy\", \"fresh\", \"vegetarian\", \"organic\"`   |\n",
    "| 3     | **Famille et groupes**           | `\"family\", \"kids\", \"friendly\", \"casual\", \"group\", \"homey\"`         |\n",
    "| 4     | **Cuisine locale et raffin√©e**   | `\"gourmet\", \"chef\", \"local\", \"authentic\", \"seasonal\", \"refined\"`   |\n",
    "| 5     | **Ambiance internationale / bar**| `\"cocktails\", \"music\", \"dance\", \"international\", \"nightlife\", \"lounge\"` |\n",
    "\n",
    "---\n",
    "\n",
    "Ces th√®mes permettent d‚Äôinterpr√©ter la s√©mantique de chaque segment automatiquement identifi√© par LDA. Ils refl√®tent des profils distincts d‚Äô√©tablissements : des restaurants gastronomiques traditionnels √† la restauration rapide, en passant par les bars lounge ou les restaurants familiaux.\n",
    "\n",
    "> **Pourquoi avons-nous retenu 6 topics ?**\n",
    "\n",
    "Apr√®s avoir exp√©riment√© plusieurs valeurs de K (nombre de sujets), nous avons combin√© deux approches compl√©mentaires :\n",
    "- Une **√©valuation quantitative** √† l‚Äôaide de la m√©trique de coh√©rence `c_v`, qui donne une premi√®re indication sur la qualit√© des regroupements th√©matiques.\n",
    "- Une **analyse qualitative manuelle**, fond√©e sur l‚Äôinspection des mots-cl√©s dominants et la d√©tection de redondances entre sujets.\n",
    "\n",
    "####  Courbe de coh√©rence (score `c_v`) selon le nombre de topics\n",
    "\n",
    "Afin de visualiser l‚Äô√©volution de la coh√©rence en fonction du nombre de sujets, nous avons trac√© la courbe suivante :\n",
    "\n",
    "![Courbe de coh√©rence LDA](rapport/opti_topic.png)\n",
    "\n",
    "> *Figure : Score de coh√©rence `c_v` en fonction du nombre de topics (K). Le point K=6 correspond au mod√®le retenu.*\n",
    "\n",
    "\n",
    "La courbe montre une **tendance g√©n√©rale √† la hausse** du score de coh√©rence √† mesure que le nombre de topics augmente, mais cette progression est **irr√©guli√®re**. Plusieurs pics locaux apparaissent (notamment √† K=5, K=12 ou K=17), tandis que d'autres valeurs interm√©diaires montrent un **recul temporaire de la coh√©rence**. Cela sugg√®re que le mod√®le gagne en complexit√© sans n√©cessairement am√©liorer la qualit√© des regroupements th√©matiques.\n",
    "\n",
    "Nous avons donc combin√© cette √©valuation automatique avec une **analyse manuelle** des sujets g√©n√©r√©s. En explorant les topics obtenus pour diff√©rentes valeurs de K, nous avons constat√© qu‚Äôau-del√† de **6 sujets**, des **doublons th√©matiques** apparaissaient r√©guli√®rement (ex. : deux groupes sur la gastronomie ou le vin), rendant l‚Äôinterpr√©tation moins claire.\n",
    "\n",
    "Afin d‚Äôobtenir des th√®mes distincts et compr√©hensibles, nous avons utilis√© **ChatGPT** pour interpr√©ter les mots-cl√©s les plus repr√©sentatifs de chaque topic. Cela nous a permis d‚Äôidentifier √† K=6 une **structure th√©matique claire**, avec des segments diff√©renci√©s et coh√©rents avec la r√©alit√© des profils restaurants (gastronomie, famille, rapide, bar, sant√©, etc.).\n",
    "\n",
    "Ce choix nous a permis d‚Äôallier **lisibilit√©**, **interpr√©tabilit√©** et **richesse th√©matique**, tout en √©vitant la surcharge cognitive d‚Äôun trop grand nombre de sujets. Ces informations ont √©t√© int√©gr√©es dans notre **dashboard interactif (Task 3)**, qui permet d‚Äôexplorer dynamiquement les th√®mes identifi√©s et leur r√©partition g√©ographique en France.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1807a59",
   "metadata": {},
   "source": [
    "## 2. Task 2.1 ‚Äì Classification supervis√©e\n",
    "\n",
    "### 2.1 Objectif de la t√¢che\n",
    "\n",
    "L'objectif de cette t√¢che est de construire un mod√®le de classification capable de pr√©dire si un restaurant sera **bien not√© ou non** √† partir de ses descripteurs textuels (`keywords`). Pour cela, nous avons formul√© une t√¢che de **classification binaire** en utilisant la variable `avg_rating`.\n",
    "\n",
    "Nous avons d√©fini la variable cible (`target`) de la mani√®re suivante :\n",
    "- **Classe 1 (positif)** : si `avg_rating >= 4.0`  \n",
    "- **Classe 0 (n√©gatif)** : si `avg_rating < 4.0`\n",
    "\n",
    "Cette formulation refl√®te un cas d‚Äôusage r√©aliste : recommander ou filtrer automatiquement des √©tablissements de qualit√© √† partir de leur profil descriptif.\n",
    "\n",
    "### 2.2 M√©thodologie\n",
    "\n",
    "Nous avons suivi les √©tapes classiques d‚Äôun pipeline de classification supervis√©e :\n",
    "\n",
    "1. **Pr√©paration des donn√©es**\n",
    "   - Texte vectoris√© selon 4 m√©thodes : TF-IDF, BoW, Word2Vec, Doc2Vec\n",
    "   - R√©duction de dimension via `SelectKBest(chi2)` ou `PCA` selon les cas\n",
    "   - Normalisation automatique via les mod√®les\n",
    "\n",
    "2. **Division en ensembles d‚Äôapprentissage et de test**\n",
    "   - Utilisation de `train_test_split` avec un ratio 80% / 20%\n",
    "   - `random_state=42` pour reproductibilit√©\n",
    "   - Strate selon la variable cible pour conserver l'√©quilibre\n",
    "\n",
    "3. **√âvaluation par m√©triques standards**\n",
    "   - Accuracy, F1-score (macro et par classe)\n",
    "   - Matrice de confusion\n",
    "   - Aire sous la courbe ROC (AUC)\n",
    "\n",
    "### 2.3 Mod√®les test√©s\n",
    "\n",
    "Nous avons test√© plusieurs algorithmes de classification couvrant une diversit√© d‚Äôapproches (lin√©aires, probabilistes, non lin√©aires, r√©seaux de neurones), afin d‚Äôidentifier ceux les plus adapt√©s √† notre t√¢che de pr√©diction binaire.\n",
    "\n",
    "La **r√©gression logistique** a √©t√© notre point de d√©part en tant que mod√®le de r√©f√©rence simple, lin√©aire et interpr√©table. Elle a donn√© de bons r√©sultats sur les vecteurs creux comme TF-IDF, mais sa capacit√© √† mod√©liser des relations complexes reste limit√©e, ce qui peut p√©naliser ses performances sur des donn√©es moins lin√©aires.\n",
    "\n",
    "Le **Random Forest** s‚Äôest montr√© particuli√®rement robuste : en combinant plusieurs arbres de d√©cision, il capture naturellement des interactions entre variables, m√™me bruit√©es. Il tol√®re bien les donn√©es peu normalis√©es, et a bien fonctionn√© avec les vecteurs denses (Word2Vec). En revanche, il est moins rapide √† entra√Æner, consomme plus de m√©moire, et son fonctionnement interne est plus difficile √† interpr√©ter.\n",
    "\n",
    "Nous avons √©galement test√© un **classifieur √† base de gradient boosting**, connu pour ses performances sur des jeux de donn√©es structur√©s. Il a offert de bons r√©sultats, mais au prix d‚Äôun **temps d'entra√Ænement √©lev√©**, notamment avec des repr√©sentations textuelles √† forte dimension.\n",
    "\n",
    "Le **LinearSVC** (Support Vector Classifier lin√©aire) s‚Äôest impos√© comme l‚Äôun des meilleurs mod√®les sur les vecteurs TF-IDF. Tr√®s efficace en haute dimension, il maximise la marge entre classes, ce qui am√©liore la g√©n√©ralisation. Il est rapide, robuste, et moins sensible aux outliers que d‚Äôautres mod√®les lin√©aires. Son principal d√©faut reste qu‚Äôil ne produit pas directement de probabilit√©s, ce qui peut limiter son usage dans des applications n√©cessitant des scores calibr√©s.\n",
    "\n",
    "Le **Naive Bayes**, rapide et facile √† entra√Æner, s‚Äôest montr√© comp√©titif avec BoW et TF-IDF. Cependant, ses hypoth√®ses d‚Äôind√©pendance entre les mots sont trop fortes, et sa performance chute rapidement avec des vecteurs denses ou en pr√©sence de corr√©lations entre termes.\n",
    "\n",
    "Le **K-Nearest Neighbors** (KNN), quant √† lui, offre une approche intuitive : un point est class√© selon ses voisins les plus proches. Il fonctionne bien sur des vecteurs compacts comme Word2Vec, mais il est lent √† l‚Äôinf√©rence (car le calcul des distances se fait en temps r√©el) et sensible au bruit ou aux donn√©es d√©s√©quilibr√©es.\n",
    "\n",
    "Enfin, le **Multi-Layer Perceptron (MLP)** repr√©sente la solution la plus expressive, capable d‚Äôapprendre des non-lin√©arit√©s complexes. Il a tr√®s bien fonctionn√© avec Word2Vec et Doc2Vec, mais il n√©cessite un ajustement fin des hyperparam√®tres, un temps d‚Äôentra√Ænement important, et est plus sensible au surapprentissage.\n",
    "\n",
    "En r√©sum√©, chaque mod√®le pr√©sente des compromis entre **performance brute**, **vitesse**, **complexit√©**, et **interpr√©tabilit√©**, et notre √©valuation a permis de retenir ceux les plus adapt√©s √† notre cas d‚Äôusage, en particulier **LinearSVC et Random Forest**, selon le type de vecteur utilis√©.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 R√©duction de dimension\n",
    "\n",
    "#### S√©lection supervis√©e (`SelectKBest` avec chi¬≤)\n",
    "- Appliqu√©e aux vecteurs creux (TF-IDF, BoW)\n",
    "- S√©lection des **300 features les plus discriminantes**\n",
    "- Gain observ√© : **r√©duction du sur-apprentissage** et **temps d‚Äôentra√Ænement r√©duit**\n",
    "\n",
    "#### Extraction non supervis√©e (`PCA`)\n",
    "- Appliqu√©e aux vecteurs denses (Word2Vec, Doc2Vec)\n",
    "- R√©duction √† **50 composantes principales**\n",
    "- Permet d‚Äôextraire la structure latente des documents\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5 R√©sultats comparatifs\n",
    "\n",
    "Nous avons compar√© chaque combinaison **[vecteur + mod√®le]**. Les r√©sultats sont synth√©tis√©s ci-dessous.\n",
    "\n",
    "### 2.5 R√©sultats et comparaison des mod√®les (avec TF-IDF)\n",
    "\n",
    "Nous pr√©sentons ici les performances des mod√®les test√©s avec la vectorisation **TF-IDF**, qui s‚Äôest r√©v√©l√©e √™tre la plus efficace globalement.\n",
    "\n",
    "#### üìä R√©sultats globaux (TF-IDF)\n",
    "\n",
    "| Mod√®le               | Accuracy | F1_class_0 | F1_macro | AUC     |\n",
    "|----------------------|----------|------------|----------|---------|\n",
    "| **Linear SVC**       | 0.834    | **0.370**  | **0.637**| ‚Äî       |\n",
    "| Logistic Regression  | 0.801    | 0.329      | 0.606    | 0.759   |\n",
    "| MLP (Neural Net)     | 0.884    | 0.241      | 0.589    | 0.640   |\n",
    "| Random Forest        | 0.879    | 0.116      | 0.525    | 0.598   |\n",
    "| Gradient Boosting    | 0.893    | 0.069      | 0.506    | 0.667   |\n",
    "| KNN                  | 0.889    | 0.045      | 0.493    | 0.587   |\n",
    "| **Naive Bayes**      | **0.897**| 0.000      | 0.473    | **0.807**|\n",
    "\n",
    "> *Tableau : R√©sultats des principaux mod√®les entra√Æn√©s sur les vecteurs TF-IDF. L'accent est mis sur la F1-score classe 0, essentielle pour pr√©dire les restaurants mal not√©s.*\n",
    "\n",
    "---\n",
    "\n",
    "#### Courbe ROC ‚Äì TF-IDF\n",
    "\n",
    "![Courbe ROC TF-IDF](rapport/tf_courbe_auc.png)\n",
    "\n",
    "\n",
    "> *Figure : Comparaison des courbes ROC pour les mod√®les TF-IDF. Naive Bayes affiche l‚ÄôAUC la plus √©lev√©e mais pr√©sente un fort biais de pr√©diction.*\n",
    "\n",
    "---\n",
    "\n",
    "####  Matrices de confusion\n",
    "\n",
    "##### üîπ Naive Bayes (TF-IDF)\n",
    "\n",
    "![Confusion Matrix ‚Äì Naive Bayes](rapport/tf_naive.png)\n",
    "\n",
    "> Le mod√®le **ne pr√©dit jamais la classe 0** : tous les restaurants sont class√©s comme \"bien not√©s\", ce qui explique sa F1_score = 0 sur cette classe, malgr√© une AUC √©lev√©e.\n",
    "\n",
    "##### üîπ Random Forest (TF-IDF)\n",
    "\n",
    "![Confusion Matrix ‚Äì Random Forest](rapport/tf_random.png)\n",
    "\n",
    "> L‚Äôarbre al√©atoire pr√©dit la classe 0, mais avec beaucoup de **faux positifs**. Son F1_class_0 reste faible (0.116), malgr√© une meilleure balance que Naive Bayes.\n",
    "\n",
    "### 2.5 R√©sultats et comparaison des mod√®les (avec BoW)\n",
    "\n",
    "Nous pr√©sentons ici les performances des mod√®les test√©s avec la vectorisation **Bag of Words (BoW)**. Bien que plus simple que TF-IDF, cette m√©thode s‚Äôest r√©v√©l√©e comp√©titive dans plusieurs cas, notamment avec Naive Bayes.\n",
    "\n",
    "####  R√©sultats globaux (BoW)\n",
    "\n",
    "| Mod√®le               | Accuracy | F1_class_0 | F1_macro | AUC     |\n",
    "|----------------------|----------|------------|----------|---------|\n",
    "| **Naive Bayes**      | **0.910**| **0.393**  | **0.672**| **0.842**|\n",
    "| Logistic Regression  | 0.788    | 0.353      | 0.613    | 0.767   |\n",
    "| Linear SVC           | 0.806    | 0.329      | 0.608    | ‚Äî       |\n",
    "| MLP (Neural Net)     | 0.871    | 0.210      | 0.570    | 0.654   |\n",
    "| Random Forest        | 0.868    | 0.074      | 0.501    | 0.651   |\n",
    "| Gradient Boosting    | 0.893    | 0.024      | 0.483    | 0.671   |\n",
    "| KNN                  | 0.892    | 0.000      | 0.471    | 0.532   |\n",
    "\n",
    "> *Tableau : Performances des mod√®les avec BoW. Naive Bayes ressort comme le mod√®le dominant sur toutes les m√©triques cl√©s, y compris la classe minoritaire.*\n",
    "\n",
    "---\n",
    "\n",
    "####  Courbe ROC ‚Äì BoW\n",
    "\n",
    "![Courbe ROC BoW](rapport/bow_auc.png)\n",
    "\n",
    "> *Figure : Comparaison des courbes ROC pour les mod√®les BoW. Naive Bayes montre la meilleure s√©paration (AUC = 0.84), suivi de Logistic Regression.*\n",
    "\n",
    "---\n",
    "\n",
    "####  Matrices de confusion\n",
    "\n",
    "##### üîπ Naive Bayes (BoW)\n",
    "\n",
    "![Confusion Matrix ‚Äì Naive Bayes](rapport/bow_naive.png)\n",
    "\n",
    "> Contrairement √† sa version TF-IDF, Naive Bayes ici **r√©ussit √† pr√©dire la classe 0** (22 cas sur 78), tout en gardant une bonne pr√©cision globale.\n",
    "\n",
    "##### üîπ Random Forest (BoW)\n",
    "\n",
    "![Confusion Matrix ‚Äì Random Forest](rapport/bow_randomm.png)\n",
    "\n",
    "> Random Forest d√©tecte tr√®s peu de cas n√©gatifs (classe 0), avec une forte **asym√©trie de pr√©diction**. Cela confirme son **F1_class_0 tr√®s faible (0.074)** malgr√© une bonne accuracy globale.\n",
    "\n",
    "---\n",
    "\n",
    "###  Analyse comparative des mod√®les avec BoW\n",
    "\n",
    "Les performances observ√©es avec la vectorisation BoW soulignent plusieurs √©l√©ments importants :\n",
    "\n",
    "- **Naive Bayes** atteint la **meilleure accuracy (91%)**, **meilleure F1_class_0 (0.393)**, **meilleure F1_macro (0.672)** et **meilleure AUC (0.84)**. Il est donc, ici, **le mod√®le le plus performant**, et de loin, notamment gr√¢ce √† la simplicit√© de la repr√©sentation BoW qu‚Äôil exploite parfaitement.\n",
    "\n",
    "- **Logistic Regression** confirme sa robustesse avec une bonne **F1_class_0 (0.353)** et un **AUC √©lev√© (0.77)**. C‚Äôest un **excellent compromis** entre complexit√© mod√©r√©e et performance.\n",
    "\n",
    "- **Linear SVC**, sans AUC disponible, reste comp√©titif mais **moins efficace que sur TF-IDF**.\n",
    "\n",
    "- Les mod√®les plus complexes comme **Random Forest**, **Gradient Boosting** ou **MLP** sont ici **surclass√©s par des mod√®les plus simples**. Leurs performances sur la classe minoritaire restent d√©cevantes (F1_class_0 < 0.1 dans certains cas).\n",
    "\n",
    "---\n",
    "\n",
    "###  Conclusion sur les r√©sultats BoW\n",
    "\n",
    "Avec la vectorisation BoW, c‚Äôest **Naive Bayes** qui s‚Äôimpose comme le **mod√®le le plus performant**, contrairement √† TF-IDF o√π il √©chouait √† d√©tecter la classe minoritaire. Cela confirme que le **choix du mod√®le d√©pend √©troitement du type de repr√©sentation vectorielle**.\n",
    "\n",
    "BoW, bien que basique, s‚Äôav√®re tr√®s efficace coupl√© √† un mod√®le probabiliste adapt√© √† ses hypoth√®ses, comme Naive Bayes. En revanche, pour les approches plus complexes ou non-lin√©aires, cette repr√©sentation semble trop simpliste pour exprimer correctement les nuances textuelles n√©cessaires √† une classification fine.\n",
    "\n",
    "###  2.5 R√©sultats et comparaison des mod√®les (avec Word2Vec)\n",
    "\n",
    "Nous pr√©sentons ici les performances des mod√®les test√©s avec la vectorisation **Word2Vec**, qui encode chaque mot comme un vecteur dense appris √† partir du contexte. Pour chaque restaurant, nous avons pris la moyenne des vecteurs mots pr√©sents.\n",
    "\n",
    "####  R√©sultats globaux (Word2Vec)\n",
    "\n",
    "| Mod√®le               | Accuracy | F1_class_0 | F1_macro | AUC     |\n",
    "|----------------------|----------|------------|----------|---------|\n",
    "| Linear SVC           | 0.585    | 0.245      | 0.479    | ‚Äî       |\n",
    "| Logistic Regression  | 0.594    | 0.238      | 0.481    | 0.607   |\n",
    "| KNN                  | 0.892    | 0.089      | 0.516    | 0.563   |\n",
    "| Gradient Boosting    | 0.899    | 0.072      | 0.509    | 0.657   |\n",
    "| MLP (Neural Net)     | 0.899    | 0.025      | 0.486    | 0.663   |\n",
    "| Random Forest        | 0.897    | 0.000      | 0.473    | 0.646   |\n",
    "\n",
    "> *Tableau : R√©sultats obtenus avec Word2Vec. Les mod√®les semblent obtenir une bonne accuracy, mais leur capacit√© √† d√©tecter la classe minoritaire reste limit√©e.*\n",
    "\n",
    "---\n",
    "\n",
    "####  Courbe ROC ‚Äì Word2Vec\n",
    "\n",
    "![Courbe ROC Word2Vec](rapport/w_courbe_auc.png)\n",
    "\n",
    "> *Figure : Comparaison des courbes ROC pour les mod√®les Word2Vec. Les meilleurs AUC sont obtenus par MLP et Gradient Boosting (~0.66).*\n",
    "\n",
    "---\n",
    "\n",
    "####  Matrices de confusion\n",
    "\n",
    "##### üîπ Gradient Boosting (Word2Vec)\n",
    "\n",
    "![Confusion Matrix ‚Äì Gradient Boosting](rapport/w_gb.png)\n",
    "\n",
    "> Le mod√®le parvient √† identifier une petite partie de la classe 0 (3 pr√©dictions correctes), mais reste fortement biais√© vers la classe majoritaire.\n",
    "\n",
    "##### üîπ MLP (Word2Vec)\n",
    "\n",
    "![Confusion Matrix ‚Äì MLP](rapport/w_mlp.png)\n",
    "\n",
    "> Le r√©seau de neurones ne pr√©dit **pratiquement jamais** la classe 0, malgr√© un AUC raisonnable. Cela explique sa F1_class_0 tr√®s faible (0.025).\n",
    "\n",
    "---\n",
    "\n",
    "###  Analyse comparative des mod√®les avec Word2Vec\n",
    "\n",
    "L‚Äôutilisation de **Word2Vec** n‚Äôa pas apport√© les gains esp√©r√©s par rapport √† TF-IDF ou BoW. Plusieurs constats peuvent √™tre faits :\n",
    "\n",
    "- Les **mod√®les lin√©aires** comme **Linear SVC** et **Logistic Regression** affichent des scores modestes (accuracy ~0.59), mais avec une **F1_class_0 autour de 0.24**, ce qui reste acceptable pour cette t√¢che d√©s√©quilibr√©e.\n",
    "\n",
    "- Les **mod√®les complexes (MLP, GB, RF)**, bien que tr√®s pr√©cis globalement (accuracy ~0.89), **√©chouent √† identifier correctement les mauvais restaurants (classe 0)**. Leurs matrices de confusion le confirment.\n",
    "\n",
    "- **MLP**, par exemple, affiche un AUC correct (0.66) mais **ne pr√©dit la classe 0 qu‚Äôune seule fois**, le rendant peu utile dans une logique de filtrage/recommandation √©quilibr√©e.\n",
    "\n",
    "- **KNN** et **Random Forest** obtiennent des r√©sultats similaires : **accuracy forte**, mais **F1_class_0 < 0.1**, donc tr√®s faible sensibilit√© aux mauvais restaurants.\n",
    "\n",
    "---\n",
    "\n",
    "###  Conclusion sur les r√©sultats Word2Vec\n",
    "\n",
    "Word2Vec, malgr√© sa richesse s√©mantique th√©orique, s‚Äôest r√©v√©l√© **moins performant que pr√©vu** dans ce contexte. La principale raison est la **structure tr√®s courte et cat√©gorielle des donn√©es** (`keywords`), qui ne b√©n√©ficie pas pleinement des relations contextuelles apprises par Word2Vec.\n",
    "\n",
    "Les performances globales sont **fortement biais√©es vers la classe majoritaire**, ce qui entra√Æne une **perte d‚Äôutilit√©** pour un syst√®me de recommandation qui doit justement pouvoir **discriminer les √©tablissements moins appr√©ci√©s**.\n",
    "\n",
    "Ainsi, malgr√© un gain potentiel en expressivit√© vectorielle, **Word2Vec n‚Äôa pas surpass√© les m√©thodes classiques**, et reste secondaire dans notre pipeline.\n",
    "\n",
    "###  2.6 R√©sultats et comparaison des mod√®les (avec Doc2Vec)\n",
    "\n",
    "Nous pr√©sentons ici les performances obtenues avec **Doc2Vec**, une m√©thode qui apprend un vecteur dense propre √† chaque document (restaurant), au lieu d‚Äôagr√©ger des vecteurs mots.\n",
    "\n",
    "####  R√©sultats globaux (Doc2Vec)\n",
    "\n",
    "| Mod√®le               | Accuracy | F1_class_0 | F1_macro | AUC     |\n",
    "|----------------------|----------|------------|----------|---------|\n",
    "| Linear SVC           | 0.635    | 0.277      | 0.516    | ‚Äî       |\n",
    "| Logistic Regression  | 0.640    | 0.268      | 0.514    | 0.711   |\n",
    "| MLP (Neural Net)     | 0.884    | 0.170      | 0.553    | 0.650   |\n",
    "| KNN                  | 0.890    | 0.162      | 0.552    | 0.572   |\n",
    "| Gradient Boosting    | 0.895    | 0.070      | 0.506    | 0.643   |\n",
    "| Random Forest        | 0.897    | 0.000      | 0.473    | 0.653   |\n",
    "\n",
    "> *Tableau : R√©sultats des mod√®les avec vecteurs Doc2Vec. Bien que l‚Äôaccuracy soit souvent √©lev√©e, la capacit√© √† pr√©dire la classe 0 reste globalement limit√©e.*\n",
    "\n",
    "---\n",
    "\n",
    "####  Courbe ROC ‚Äì Doc2Vec\n",
    "\n",
    "![Courbe ROC Doc2Vec](rapport/d_auc.png)\n",
    "\n",
    "> *Figure : Comparaison des courbes ROC pour Doc2Vec. Le meilleur AUC est obtenu par la r√©gression logistique (0.71), devant MLP et Gradient Boosting.*\n",
    "\n",
    "---\n",
    "\n",
    "####  Matrices de confusion\n",
    "\n",
    "##### üîπ Logistic Regression (Doc2Vec)\n",
    "\n",
    "![Confusion Matrix ‚Äì Logistic Regression](rapport/d_lin.png)\n",
    "\n",
    "> Ce mod√®le arrive √† √©quilibrer relativement les classes. Il d√©tecte correctement une partie non n√©gligeable des classes 0 (50 sur 78), mais rate encore 245 exemples.\n",
    "\n",
    "##### üîπ KNN (Doc2Vec)\n",
    "\n",
    "![Confusion Matrix ‚Äì KNN](rapport/d_knn.png)\n",
    "\n",
    "> Bien qu‚Äôil offre une bonne accuracy, KNN tend √† pr√©dire la classe majoritaire. La classe 0 n‚Äôest d√©tect√©e que dans 8 cas sur 78.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Analyse comparative des mod√®les avec Doc2Vec\n",
    "\n",
    "L‚Äôapproche **Doc2Vec** propose une mod√©lisation plus riche, en capturant le sens global d‚Äôun document plut√¥t que le cumul des mots. Cela dit, dans notre contexte ‚Äî des documents tr√®s courts compos√©s uniquement de `keywords` ‚Äî cette richesse reste sous-exploit√©e.\n",
    "\n",
    "- **Linear SVC** et **Logistic Regression** affichent des performances relativement stables. Logistic Regression s'en tire le mieux avec un **AUC de 0.71**, et un **F1_class_0 autour de 0.27**, ce qui reste le meilleur score de cette s√©rie.\n",
    "\n",
    "- Les mod√®les non-lin√©aires comme **MLP** et **KNN** atteignent une **accuracy √©lev√©e (~0.89)**, mais souffrent encore d‚Äôun **d√©s√©quilibre de classes**, avec une **sous-d√©tection forte des mauvais restaurants**.\n",
    "\n",
    "- Les **Random Forest** et **Gradient Boosting** affichent une absence quasi-totale de pr√©diction pour la classe 0. Malgr√© une AUC correcte (~0.65), ils **√©chouent totalement** sur cette classe.\n",
    "\n",
    "> √Ä noter que **la meilleure combinaison ici reste Doc2Vec + Logistic Regression**, mais elle ne surpasse pas TF-IDF en termes de F1_class_0.\n",
    "\n",
    "---\n",
    "\n",
    "###  Conclusion sur les r√©sultats Doc2Vec\n",
    "\n",
    "L‚Äôapproche Doc2Vec s‚Äôav√®re **trop sophistiqu√©e pour un corpus compos√© de cha√Ænes courtes et peu ambigu√´s** comme les `keywords`. Son avantage sur des documents longs ne se traduit pas ici par de meilleures performances.\n",
    "\n",
    "Elle souffre du m√™me probl√®me que Word2Vec : **les mod√®les interpr√®tent mal la classe 0**, ce qui les rend inadapt√©s √† des syst√®mes de recommandation √©quilibr√©s. Enfin, son **co√ªt de calcul est significatif**, pour un **gain limit√©**, ce qui renforce notre pr√©f√©rence pour **TF-IDF** dans ce cas d‚Äôusage.\n",
    "\n",
    "\n",
    "\n",
    "###  Analyse comparative\n",
    "\n",
    "La comparaison des mod√®les fait appara√Ætre plusieurs **compromis** :\n",
    "\n",
    "- **Naive Bayes** obtient le **meilleur score AUC (0.81)**, et la **meilleure accuracy (0.897)**, mais il est **incapable de pr√©dire correctement les mauvais restaurants** (classe 0), ce qui **le rend inutilisable** pour une application de recommandation √©quilibr√©e.\n",
    "  \n",
    "- **Linear SVC** a le **meilleur F1_class_0 (0.370)** et le **meilleur F1_macro (0.637)**, ce qui indique une **meilleure capacit√© √† distinguer les deux classes** ‚Äî y compris les minoritaires. M√™me sans score de probabilit√© (pas d‚ÄôAUC), son **√©quilibre entre pr√©cision et robustesse** en fait le **mod√®le le plus fiable** pour notre t√¢che.\n",
    "\n",
    "- **Logistic Regression** est un bon compromis : des scores corrects partout, une AUC de 0.76 et un F1_class_0 satisfaisant (0.33), ce qui le rend viable si une probabilit√© explicite est n√©cessaire.\n",
    "\n",
    "- **Random Forest**, bien qu‚Äôint√©ressant sur les features complexes, souffre ici d‚Äôun **F1_class_0 trop faible (0.116)**, ce qui diminue sa pertinence dans notre cas.\n",
    "\n",
    "- Les mod√®les comme **KNN** ou **Gradient Boosting** ont un bon score global, mais **√©chouent sur la classe minoritaire** (F1 < 0.1), les rendant peu adapt√©s √† une t√¢che d√©s√©quilibr√©e.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###  Conclusion g√©n√©rale sur la comparaison des mod√®les et vectorisations\n",
    "\n",
    "L‚Äôanalyse crois√©e de l‚Äôensemble des r√©sultats obtenus avec les diff√©rentes m√©thodes de vectorisation (TF-IDF, BoW, Word2Vec, Doc2Vec) et mod√®les de classification supervis√©e permet de tirer plusieurs enseignements concrets.\n",
    "\n",
    "####  Performances globales\n",
    "\n",
    "Les meilleurs compromis entre pr√©cision globale (accuracy) et capacit√© √† identifier correctement les restaurants **mal not√©s** (F1_class_0) ont √©t√© atteints avec :\n",
    "\n",
    "- **TF-IDF + LinearSVC** : F1_class_0 = 0.37, F1_macro = 0.637  \n",
    "- **BoW + Naive Bayes** : F1_class_0 = 0.392, F1_macro = 0.672, AUC = 0.84  \n",
    "- **TF-IDF + Logistic Regression** : F1_class_0 = 0.329, F1_macro = 0.606  \n",
    "\n",
    "Les scores les plus √©lev√©s d‚Äô**AUC (area under ROC curve)** sont observ√©s avec **BoW + Naive Bayes** et **TF-IDF + Logistic Regression**, indiquant une bonne capacit√© √† distinguer les classes au niveau probabiliste.\n",
    "\n",
    "####  Pourquoi certaines AUC sont √† `NaN` ?\n",
    "\n",
    "Les valeurs `NaN` dans la colonne **AUC** (Area Under the Curve) proviennent du fait que certains mod√®les (notamment **LinearSVC**) ne disposent pas de m√©thode `predict_proba()` dans leur impl√©mentation de Scikit-learn. Cette m√©thode est n√©cessaire pour calculer l‚ÄôAUC, car elle fournit des **probabilit√©s de classe**. En son absence, seule la pr√©diction binaire (`predict()`) est disponible, ce qui emp√™che la g√©n√©ration de la courbe ROC et donc le calcul de l‚Äôaire sous celle-ci.\n",
    "\n",
    "Cela explique pourquoi **LinearSVC** appara√Æt avec un `NaN` dans la colonne AUC, malgr√© des performances tout √† fait comp√©titives en accuracy et F1-score.\n",
    "\n",
    "####  Comparaison des m√©thodes de vectorisation\n",
    "\n",
    "- **TF-IDF** s‚Äôimpose comme la m√©thode la plus **fiable, stable et efficace**, notamment avec des mod√®les lin√©aires. Elle combine une bonne pr√©cision globale avec une bonne sensibilit√© √† la classe minoritaire.\n",
    "- **BoW**, bien que simpliste, donne d‚Äôexcellents r√©sultats avec **Naive Bayes**, prouvant qu‚Äôun mod√®le simple peut suffire dans un contexte bien pr√©par√©.\n",
    "- **Word2Vec** et **Doc2Vec** montrent des performances globales correctes en accuracy, mais souvent faibles en **F1_class_0**, ce qui montre leur difficult√© √† pr√©dire les restaurants mal not√©s. De plus, leur co√ªt computationnel est √©lev√©.\n",
    "\n",
    "---\n",
    "\n",
    "###  Conclusion finale\n",
    "\n",
    "En r√©sum√©, **la combinaison TF-IDF + LinearSVC** est le meilleur choix dans notre cas d‚Äôusage : elle offre un tr√®s bon **F1 sur la classe 0**, une **mise en ≈ìuvre rapide**, une **interpr√©tabilit√© correcte**, et une bonne **g√©n√©ralisation**.\n",
    "\n",
    "Les repr√©sentations vectorielles denses (Word2Vec, Doc2Vec), bien que prometteuses th√©oriquement, ne sont pas adapt√©es √† un corpus aussi court et structur√© que le n√¥tre. Le **rapport co√ªt / performance** ne justifie pas leur usage ici.\n",
    "\n",
    "Enfin, **l‚Äôutilisation de plusieurs m√©triques** (accuracy, F1_class_0, AUC) a permis d‚Äôavoir une vision compl√®te et √©quilibr√©e des performances, en particulier dans un contexte d√©s√©quilibr√© o√π la **classe minoritaire (restaurants mal not√©s)** est la plus difficile √† d√©tecter, mais aussi la plus utile pour notre syst√®me de recommandation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e4be7",
   "metadata": {},
   "source": [
    "## 3. Task 3 ‚Äì Tableaux de bord interactifs avec Dash\n",
    "\n",
    "###  Objectif g√©n√©ral\n",
    "\n",
    "Dans une optique de lisibilit√©, d‚Äôinterpr√©tabilit√© et d'interaction, nous avons d√©velopp√© **deux tableaux de bord interactifs** avec la biblioth√®que **Dash (Plotly)**. Ces outils permettent :\n",
    "\n",
    "- D'explorer les **sujets th√©matiques extraits par LDA** de mani√®re g√©ographique et interpr√©table\n",
    "- De naviguer dans les **r√©sultats de classification supervis√©e**, en testant dynamiquement diff√©rents mod√®les et m√©thodes de vectorisation\n",
    "\n",
    ">  *Pour concevoir ces interfaces, nous avons utilis√© ChatGPT pour optimiser les callbacks, structurer les interactions et am√©liorer l‚Äôergonomie.*\n",
    "\n",
    "---\n",
    "\n",
    "###  Dashboard LDA ‚Äì Visualisation des sujets\n",
    "\n",
    "Ce tableau de bord permet d‚Äôexplorer les **sujets latents (topics)** identifi√©s par LDA, en filtrant par **ville** et en visualisant la r√©partition des th√®mes sur une **carte interactive**.\n",
    "\n",
    "#### Fonctionnalit√©s principales :\n",
    "- **Dropdown de ville** : filtrer dynamiquement les restaurants par localit√©\n",
    "- **Histogramme des sujets dominants** : voir la r√©partition des topics (0 √† 5)\n",
    "- **Carte Mapbox** : localisation des restaurants color√©s selon leur sujet\n",
    "- **Affichage des mots-cl√©s d‚Äôun topic** : aide √† l‚Äôinterpr√©tation s√©mantique\n",
    "\n",
    "#### Ce qu‚Äôon peut y voir :\n",
    "- Les th√©matiques culinaires les plus pr√©sentes dans une ville\n",
    "- Les zones g√©ographiques associ√©es √† chaque type de restaurant\n",
    "- Les descripteurs caract√©ristiques de chaque sujet (ex : \"wine bar\", \"cheap\", \"gluten free\")\n",
    "\n",
    "#### Capture d‚Äô√©cran (√† ins√©rer) :\n",
    "![Dashboard LDA ‚Äì Histogramme et carte](data/d1p1.png)\n",
    "![Dashboard LDA ‚Äì Histogramme et carte](data/d1p2.png)\n",
    "![Dashboard LDA ‚Äì Histogramme et carte](data/d1_p3.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###  Dashboard de recommandation ‚Äì Mod√®les de pr√©diction\n",
    "\n",
    "Ce second tableau de bord permet de visualiser les **restaurants pr√©dits comme bien not√©s** √† partir de leurs mots-cl√©s, en fonction du **mod√®le** et de la **m√©thode de vectorisation** s√©lectionn√©s.\n",
    "\n",
    "#### Fonctionnalit√©s principales :\n",
    "- **Dropdown de vectorisation** : TF-IDF, BoW, Word2Vec, Doc2Vec\n",
    "- **Dropdown de mod√®le** : Logistic Regression, Random Forest, SVC, MLP, etc.\n",
    "- **Carte des pr√©dictions** : restaurants pr√©dits comme \"bons\" affich√©s avec leur score\n",
    "- **Top 10 recommandations** : tableau des restaurants les mieux class√©s\n",
    "- **Top 10 pires restaurants** : possibilit√© d'afficher √©galement les moins bien not√©s\n",
    "\n",
    "#### Ce qu‚Äôon peut y voir :\n",
    "- L‚Äôimpact des choix de mod√®le/vectorisation sur les r√©sultats de recommandation\n",
    "- Les meilleurs et pires restaurants selon chaque combinaison\n",
    "- Des d√©tails pour chaque √©tablissement (ville, note, mots-cl√©s, score)\n",
    "\n",
    "#### Capture d‚Äô√©cran (√† ins√©rer) :\n",
    "![Dashboard Recommandation ‚Äì Carte](chemin/vers/image_reco_dashboard.png)\n",
    "\n",
    "---\n",
    "\n",
    "###  Int√©r√™t global\n",
    "\n",
    "Ces deux dashboards rendent le projet :\n",
    "- **Accessible** aux non-experts\n",
    "- **Explorable visuellement** en temps r√©el\n",
    "- **Facilement r√©utilisable** dans des cas pratiques de recommandation\n",
    "\n",
    "Ils peuvent √™tre adapt√©s pour des syst√®mes de filtrage, de recherche ou de notation en ligne.\n",
    "\n",
    "> Une courte vid√©o de d√©monstration est disponible en annexe pour illustrer les interactions propos√©es.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba420592",
   "metadata": {},
   "source": [
    "# Conclusion g√©n√©rale\n",
    "\n",
    "Ce projet a permis de mettre en ≈ìuvre une cha√Æne compl√®te d‚Äôanalyse automatique appliqu√©e √† des donn√©es textuelles, depuis le pr√©traitement jusqu‚Äô√† la visualisation interactive. En partant d‚Äôun jeu de donn√©es extrait de TripAdvisor, nous avons concentr√© notre analyse sur les restaurants situ√©s en France. √Ä travers un ensemble de mots-cl√©s d√©crivant les caract√©ristiques des √©tablissements, nous avons cherch√© √† extraire des informations th√©matiques pertinentes, puis √† pr√©dire la qualit√© per√ßue de chaque restaurant selon sa note moyenne.\n",
    "\n",
    "La premi√®re √©tape a consist√© √† nettoyer, structurer et transformer les donn√©es textuelles via diff√©rentes m√©thodes de vectorisation : TF-IDF, Bag of Words, Word2Vec et Doc2Vec. Nous avons pu constater que les m√©thodes simples comme TF-IDF, lorsqu‚Äôelles sont bien adapt√©es √† la nature des donn√©es (ici, des mots-cl√©s courts et synth√©tiques), restent particuli√®rement efficaces. En particulier, la combinaison TF-IDF avec un mod√®le LinearSVC s‚Äôest r√©v√©l√©e √™tre la plus stable et performante pour pr√©dire les √©tablissements bien not√©s, avec une F1-score satisfaisante sur la classe minoritaire.\n",
    "\n",
    "En parall√®le, nous avons utilis√© des m√©thodes non supervis√©es comme LDA (Latent Dirichlet Allocation) pour identifier des sujets latents dans le corpus. L‚Äôalgorithme a permis d‚Äôextraire des th√©matiques distinctes (restaurants familiaux, bars, gastronomiques, v√©g√©tariens‚Ä¶) que nous avons interpr√©t√©es √† partir des mots-cl√©s dominants. Le choix du nombre optimal de sujets a √©t√© guid√© √† la fois par une courbe de coh√©rence (c_v) et une analyse qualitative assist√©e par ChatGPT, nous permettant d‚Äô√©quilibrer lisibilit√© et richesse s√©mantique.\n",
    "\n",
    "Enfin, afin de rendre les r√©sultats accessibles √† un public non expert, nous avons d√©velopp√© deux tableaux de bord interactifs √† l‚Äôaide de Dash. Le premier permet d‚Äôexplorer g√©ographiquement les th√©matiques LDA √† travers une carte et des filtres par ville. Le second tableau de bord sert de syst√®me de recommandation visuel, o√π l‚Äôutilisateur peut tester diff√©rents mod√®les de pr√©diction et explorer les restaurants recommand√©s (ou √† √©viter), selon les scores et vecteurs associ√©s.\n",
    "\n",
    "Ce projet a donc √©t√© l‚Äôoccasion d‚Äôappliquer de mani√®re concr√®te les principaux outils du traitement automatique du langage naturel et de l‚Äôapprentissage supervis√©. Il d√©montre qu‚Äôun corpus m√™me limit√© (ici, des mots-cl√©s) peut donner lieu √† des analyses riches, des mod√®les performants et des interfaces intelligentes. Plus largement, ce travail illustre l‚Äôint√©r√™t de croiser rigueur technique, visualisation interactive et aide √† l‚Äôinterpr√©tation, pour transformer un ensemble de donn√©es textuelles en outil d‚Äôexploration et de d√©cision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb77f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
